{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd00c35bb1ba8c5f80d651bee35950e4559ae066bbf77e57e36b7e4966a21ed1b2a",
   "display_name": "Python 3.9.5 64-bit ('myenvg': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files\n",
    "bcFile = 'bcImages.npz'\n",
    "lcFile = 'lcImages.npz'\n",
    "leFile = 'leImages.npz'"
   ]
  },
  {
   "source": [
    "Custom dataset and archive manager classes, and a method returning DataLoader objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imagesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # self.X = torch.from_numpy(X).to(device='cuda', dtype=torch.float)\n",
    "        self.X = torch.from_numpy(X).to(dtype=torch.float)\n",
    "        self.X = self.X.to(memory_format=torch.contiguous_format)\n",
    "        self.n = y.shape[0]\n",
    "        # self.y = torch.from_numpy(y).to(device='cuda', dtype=torch.long)\n",
    "        self.y = torch.from_numpy(y).to(dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class fileSet():\n",
    "    def __init__(self, filename):\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        with np.load(filename, allow_pickle=True) as datafile:\n",
    "            self.X = datafile['arr_0'].transpose(0, 3, 2, 1)\n",
    "            self.y_labels = datafile['arr_1']\n",
    "        self.y = self.le.fit_transform(self.y_labels)\n",
    "        self.tts()\n",
    "\n",
    "    def tts(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=13, stratify=self.y) \n",
    "        self.train_ds = imagesDataset(X_train, y_train)\n",
    "        self.test_ds = imagesDataset(X_test, y_test)\n",
    "\n",
    "    def relabel(self, y):\n",
    "        # check if y is on cpu or else do the move / numpy conversion first\n",
    "        return self.le.inverse_transform(y.cpu().numpy())\n",
    "\n",
    "\n",
    "def loadData(fileset, batchsize=128, reshuffle=False):\n",
    "    if reshuffle:\n",
    "        fileset.tts()\n",
    "    trainLoader = DataLoader(fileset.train_ds, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "    testLoader = DataLoader(fileset.test_ds, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "    return trainLoader, testLoader"
   ]
  },
  {
   "source": [
    "Loading the breast cancer image dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcI = fileSet(bcFile)\n",
    "trainLoader, testLoader = loadData(bcI, batchsize=500)"
   ]
  },
  {
   "source": [
    "based on code from PyTorch Tutorial  \n",
    "https://pytorch.org/tutorials/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
    "        # self.conv3 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(10580, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 6) # number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# net = Net().cuda()\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([120, 3, 100, 100])\n",
      "torch.Size([120, 10580])\n",
      "torch.Size([120, 3, 100, 100])\n",
      "torch.Size([120, 10580])\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        if i == 0:\n",
    "            print(inputs.shape)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([31, 10580])\n72\nAccuracy of the network on the test images: 25 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(lcI.test_ds.n)\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "source": [
    "Given several runs of this net with several different hyperparameters (viz. number of conv layers, output sizes of each conv layer, kernel sizes, fe layer sizes), the best the net performs is barely above chance (16%) accuracy."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}